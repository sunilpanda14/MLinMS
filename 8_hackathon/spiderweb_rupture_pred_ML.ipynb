{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression template\n",
    "\n",
    "This follows https://auto.gluon.ai/stable/tutorials/tabular/tabular-quick-start.html\n",
    "\n",
    "Work through the notebook cells and change for your project\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pandas numpy autogluon ipywidgets git+https://github.com/Ramprasad-Group/psmiles.git\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from psmiles import PolymerSmiles as PS\n",
    "from sklearn.model_selection import train_test_split\n",
    "from autogluon.tabular import TabularPredictor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data and fingerprint\n",
    "\n",
    "- Create another notebook \"data.ipynb\". Synthesize, modify, manipulate, and save your data as pandas dataframe in this notebook. Finally, save your data using `pd.to_csv('data.csv)',\n",
    "- Replace the following code and load your own data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_init = pd.read_json(\n",
    "    \"https://raw.githubusercontent.com/kuennethgroup/colab_tutorials/main/lecture2/data/polymers_tend_to_crystalize.json\"\n",
    ")[[\"smiles\", \"value\"]]\n",
    "\n",
    "# Compute the fingerprints using the PSMILES package\n",
    "fps = np.vstack(df_init.smiles.apply(lambda x: PS(x).fingerprint()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scale the fingerprints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler_fps = MinMaxScaler()\n",
    "fps_scaled = scaler_fps.fit_transform(fps)\n",
    "fps_scaled = pd.DataFrame(fps_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare final data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>11</th>\n",
       "      <th>...</th>\n",
       "      <th>2035</th>\n",
       "      <th>2036</th>\n",
       "      <th>2038</th>\n",
       "      <th>2039</th>\n",
       "      <th>2041</th>\n",
       "      <th>2043</th>\n",
       "      <th>2044</th>\n",
       "      <th>2045</th>\n",
       "      <th>2047</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.483077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.449331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.343636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.201459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.217977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>427</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.321342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.257904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>429</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.293068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>430</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.218991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>431</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.075193</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>432 rows × 1369 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0         1    2    4    5    6    7    8    9   11  ...  2035  2036  \\\n",
       "0    0.0  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   \n",
       "1    0.0  0.166667  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   \n",
       "2    1.0  0.166667  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   \n",
       "3    0.0  0.166667  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   \n",
       "4    0.0  0.333333  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   \n",
       "..   ...       ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   ...   ...   \n",
       "427  0.0  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   \n",
       "428  0.0  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   \n",
       "429  0.0  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   \n",
       "430  0.0  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   \n",
       "431  0.0  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   \n",
       "\n",
       "     2038  2039  2041  2043  2044  2045  2047     value  \n",
       "0     0.0   0.0   0.0   0.0   0.0   0.0   0.0  0.483077  \n",
       "1     0.0   0.0   0.0   0.0   0.0   0.0   0.0  0.449331  \n",
       "2     0.0   0.0   0.0   0.0   0.0   0.0   0.0  0.343636  \n",
       "3     0.0   0.0   0.0   0.0   0.0   0.0   0.0  0.201459  \n",
       "4     0.0   0.0   0.0   0.0   0.0   0.0   0.0  0.217977  \n",
       "..    ...   ...   ...   ...   ...   ...   ...       ...  \n",
       "427   0.0   0.0   0.0   0.0   0.0   0.0   0.0  0.321342  \n",
       "428   0.0   0.0   0.0   0.0   0.0   0.0   0.0  0.257904  \n",
       "429   0.0   0.0   0.0   0.0   0.0   0.0   0.0  0.293068  \n",
       "430   0.0   0.0   0.0   0.0   0.0   0.0   0.0  0.218991  \n",
       "431   0.0   0.0   0.0   0.0   0.0   0.0   0.5  0.075193  \n",
       "\n",
       "[432 rows x 1369 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Concat fingerprints\n",
    "df = pd.concat((fps_scaled, df_init), axis=1)\n",
    "\n",
    "# drop smiles column because it should not be used for training\n",
    "df = df.drop(columns=\"smiles\")\n",
    "\n",
    "# Make sure they're all float\n",
    "df = df.astype(np.float32)\n",
    "\n",
    "\n",
    "# Remove columns that are zero, if any\n",
    "df = df.loc[:, (df != 0).any(axis=0)]\n",
    "\n",
    "# Normalize the tendency to crystalize\n",
    "# df['value'] = df['value'] / 100\n",
    "\n",
    "scaler_value = MinMaxScaler()\n",
    "df[\"value\"] = scaler_value.fit_transform(df[[\"value\"]])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split in train and test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>11</th>\n",
       "      <th>...</th>\n",
       "      <th>2035</th>\n",
       "      <th>2036</th>\n",
       "      <th>2038</th>\n",
       "      <th>2039</th>\n",
       "      <th>2041</th>\n",
       "      <th>2043</th>\n",
       "      <th>2044</th>\n",
       "      <th>2045</th>\n",
       "      <th>2047</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.582590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.286178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.217673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.809282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.300365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.212606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.088873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.125253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.320488</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>345 rows × 1369 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0         1    2    4    5    6    7    8    9   11  ...  2035  2036  \\\n",
       "132  0.0  0.166667  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   \n",
       "231  0.0  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   \n",
       "31   0.0  0.166667  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   \n",
       "84   0.0  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   \n",
       "296  0.0  0.166667  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   \n",
       "..   ...       ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   ...   ...   \n",
       "71   0.0  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   \n",
       "106  0.0  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.5   \n",
       "270  0.0  0.166667  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   \n",
       "348  0.0  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   \n",
       "102  0.0  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.5   \n",
       "\n",
       "     2038  2039  2041  2043  2044  2045  2047     value  \n",
       "132   0.0   0.0   0.0   0.0   0.0   0.0   0.0  0.582590  \n",
       "231   0.0   0.0   0.0   0.0   0.0   0.0   0.0  0.286178  \n",
       "31    0.0   0.0   0.0   0.0   0.0   0.0   0.0  0.217673  \n",
       "84    0.0   0.0   0.0   0.0   0.0   0.0   0.0  0.809282  \n",
       "296   0.0   0.0   0.0   0.0   0.0   0.0   0.0  0.002432  \n",
       "..    ...   ...   ...   ...   ...   ...   ...       ...  \n",
       "71    0.0   0.0   0.0   0.0   0.0   0.0   0.0  0.300365  \n",
       "106   0.0   0.0   0.0   0.0   0.0   0.0   0.0  0.212606  \n",
       "270   0.0   0.0   0.0   0.0   0.0   0.0   0.0  0.088873  \n",
       "348   0.0   0.0   1.0   0.0   0.0   0.0   0.0  0.125253  \n",
       "102   0.0   0.0   0.0   0.0   0.0   0.0   0.0  0.320488  \n",
       "\n",
       "[345 rows x 1369 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>11</th>\n",
       "      <th>...</th>\n",
       "      <th>2035</th>\n",
       "      <th>2036</th>\n",
       "      <th>2038</th>\n",
       "      <th>2039</th>\n",
       "      <th>2041</th>\n",
       "      <th>2043</th>\n",
       "      <th>2044</th>\n",
       "      <th>2045</th>\n",
       "      <th>2047</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>424</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.083604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.733685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.536279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.168221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.385083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.635488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.894406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.126752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.373835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.231557</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>87 rows × 1369 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0         1    2    4    5    6    7    8     9   11  ...  2035  2036  \\\n",
       "424  0.0  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.00  0.0  ...   0.0   0.0   \n",
       "75   0.0  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.25  0.0  ...   0.0   0.0   \n",
       "180  0.0  0.000000  0.0  0.0  0.0  0.0  0.0  0.5  0.00  0.0  ...   0.0   0.0   \n",
       "30   0.0  0.166667  0.0  0.0  0.0  0.0  0.0  0.0  0.00  0.0  ...   0.0   0.0   \n",
       "392  0.0  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.00  0.5  ...   0.0   0.0   \n",
       "..   ...       ...  ...  ...  ...  ...  ...  ...   ...  ...  ...   ...   ...   \n",
       "57   0.0  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.00  0.0  ...   0.0   0.0   \n",
       "124  0.0  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.00  0.0  ...   0.0   0.0   \n",
       "24   0.0  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.00  0.0  ...   0.0   0.0   \n",
       "17   0.0  0.166667  0.0  0.0  0.0  0.0  0.0  0.0  0.00  0.0  ...   0.0   0.0   \n",
       "66   0.0  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.00  0.0  ...   0.0   0.0   \n",
       "\n",
       "     2038  2039  2041  2043  2044  2045  2047     value  \n",
       "424   0.0   0.0   0.0   0.0   0.0   0.0   0.0  0.083604  \n",
       "75    0.0   0.0   0.0   0.0   0.0   0.0   0.0  0.733685  \n",
       "180   0.0   0.0   0.0   0.0   0.0   0.0   0.0  0.536279  \n",
       "30    0.0   0.0   0.0   0.0   0.0   0.0   0.0  0.168221  \n",
       "392   0.0   0.0   0.0   0.0   0.0   0.0   0.0  0.385083  \n",
       "..    ...   ...   ...   ...   ...   ...   ...       ...  \n",
       "57    0.0   0.0   0.0   0.0   0.0   0.0   0.0  0.635488  \n",
       "124   0.0   0.0   0.0   0.0   0.0   0.0   0.0  0.894406  \n",
       "24    0.0   0.0   0.0   0.0   0.0   0.0   0.0  0.126752  \n",
       "17    0.0   0.0   0.0   0.0   0.0   0.0   0.0  0.373835  \n",
       "66    0.0   0.0   0.0   0.0   0.0   0.0   0.0  0.231557  \n",
       "\n",
       "[87 rows x 1369 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_train, df_test = train_test_split(df, test_size=0.20, random_state=42)\n",
    "\n",
    "display(df_train)\n",
    "display(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train you AutoGluon ML model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20240625_153824\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.1.1\n",
      "Python Version:     3.10.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #117-Ubuntu SMP Fri Apr 26 12:26:49 UTC 2024\n",
      "CPU Count:          192\n",
      "Memory Avail:       939.97 GB / 1007.45 GB (93.3%)\n",
      "Disk Space Avail:   3562.20 GB / 7096.34 GB (50.2%)\n",
      "===================================================\n",
      "Presets specified: ['best_quality']\n",
      "Setting dynamic_stacking from 'auto' to True. Reason: Enable dynamic_stacking when use_bag_holdout is disabled. (use_bag_holdout=False)\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
      "DyStack is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\n",
      "\tThis is used to identify the optimal `num_stack_levels` value. Copies of AutoGluon will be fit on subsets of the data. Then holdout validation data is used to detect stacked overfitting.\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.1.1\n",
      "Python Version:     3.10.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #117-Ubuntu SMP Fri Apr 26 12:26:49 UTC 2024\n",
      "CPU Count:          192\n",
      "Memory Avail:       939.97 GB / 1007.45 GB (93.3%)\n",
      "Disk Space Avail:   3562.20 GB / 7096.34 GB (50.2%)\n",
      "===================================================\n",
      "Presets specified: ['best_quality']\n",
      "Setting dynamic_stacking from 'auto' to True. Reason: Enable dynamic_stacking when use_bag_holdout is disabled. (use_bag_holdout=False)\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
      "DyStack is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\n",
      "\tThis is used to identify the optimal `num_stack_levels` value. Copies of AutoGluon will be fit on subsets of the data. Then holdout validation data is used to detect stacked overfitting.\n",
      "\tRunning DyStack for up to 15s of the 60s of remaining time (25%).\n",
      "\t\tContext path: \"AutogluonModels/ag-20240625_153824/ds_sub_fit/sub_fit_ho\"\n",
      "Leaderboard on holdout data (DyStack):\n",
      "                    model  score_holdout  score_val              eval_metric  pred_time_test  pred_time_val  fit_time  pred_time_test_marginal  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0         LightGBM_BAG_L1      -0.143172  -0.193740  root_mean_squared_error        0.176266       0.027437  0.984998                 0.176266                0.027437           0.984998            1       True          4\n",
      "1         CatBoost_BAG_L1      -0.143525  -0.194987  root_mean_squared_error        0.569379       0.223811  1.807723                 0.569379                0.223811           1.807723            1       True          6\n",
      "2       LightGBMXT_BAG_L1      -0.144551  -0.189068  root_mean_squared_error        0.300906       0.024524  1.033957                 0.300906                0.024524           1.033957            1       True          3\n",
      "3     WeightedEnsemble_L3      -0.145042  -0.186732  root_mean_squared_error        1.436920       0.587379  4.648300                 0.002125                0.000315           0.008564            3       True         10\n",
      "4     WeightedEnsemble_L2      -0.145042  -0.186732  root_mean_squared_error        1.437022       0.587399  4.647041                 0.002227                0.000335           0.007305            2       True          7\n",
      "5       LightGBMXT_BAG_L2      -0.147782  -0.192147  root_mean_squared_error        1.793007       0.848065  5.417251                 0.149579                0.021887           0.745315            2       True          8\n",
      "6         LightGBM_BAG_L2      -0.149827  -0.195429  root_mean_squared_error        1.675747       0.847268  5.399362                 0.032318                0.021091           0.727426            2       True          9\n",
      "7  RandomForestMSE_BAG_L1      -0.165186  -0.197151  root_mean_squared_error        0.146467       0.101716  0.781764                 0.146467                0.101716           0.781764            1       True          5\n",
      "8   KNeighborsUnif_BAG_L1      -0.179982  -0.215233  root_mean_squared_error        0.208633       0.239114  0.032200                 0.208633                0.239114           0.032200            1       True          1\n",
      "9   KNeighborsDist_BAG_L1      -0.183919  -0.210714  root_mean_squared_error        0.241777       0.209575  0.031294                 0.241777                0.209575           0.031294            1       True          2\n",
      "\t1\t = Optimal   num_stack_levels (Stacked Overfitting Occurred: False)\n",
      "\t21s\t = DyStack   runtime |\t39s\t = Remaining runtime\n",
      "Starting main fit with num_stack_levels=1.\n",
      "\tFor future fit calls on this dataset, you can skip DyStack to save time: `predictor.fit(..., dynamic_stacking=False, num_stack_levels=1)`\n",
      "Beginning AutoGluon training ... Time limit = 39s\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20240625_153824\"\n",
      "Train Data Rows:    345\n",
      "Train Data Columns: 1368\n",
      "Label Column:       value\n",
      "Problem Type:       regression\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    961939.77 MB\n",
      "\tTrain Data (Original)  Memory Usage: 1.80 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 843 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUseless Original Features (Count: 100): ['6', '35', '88', '119', '136', '155', '179', '181', '207', '332', '365', '370', '384', '395', '412', '414', '421', '470', '496', '500', '517', '529', '531', '550', '610', '624', '631', '712', '731', '737', '747', '752', '765', '768', '771', '778', '786', '800', '808', '813', '815', '821', '849', '874', '876', '885', '927', '943', '962', '970', '990', '1001', '1005', '1041', '1097', '1124', '1130', '1131', '1148', '1169', '1186', '1190', '1207', '1247', '1264', '1268', '1284', '1295', '1298', '1307', '1373', '1405', '1410', '1418', '1438', '1448', '1468', '1478', '1483', '1528', '1537', '1561', '1613', '1644', '1698', '1704', '1709', '1724', '1732', '1744', '1756', '1761', '1801', '1861', '1880', '1892', '1972', '2014', '2038', '2044']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tUnused Original Features (Count: 387): ['47', '61', '67', '75', '146', '157', '163', '185', '199', '201', '204', '208', '234', '246', '254', '255', '257', '260', '262', '265', '271', '285', '304', '305', '306', '315', '317', '318', '320', '324', '341', '353', '364', '372', '377', '381', '406', '428', '445', '451', '472', '485', '490', '498', '499', '502', '509', '512', '516', '525', '527', '537', '538', '549', '558', '561', '563', '567', '568', '582', '585', '599', '600', '603', '629', '633', '638', '643', '644', '648', '649', '653', '654', '655', '657', '658', '659', '663', '666', '675', '681', '701', '707', '723', '726', '729', '741', '750', '764', '767', '772', '774', '776', '779', '796', '797', '798', '802', '810', '811', '812', '822', '825', '828', '838', '839', '845', '853', '860', '863', '871', '877', '880', '895', '897', '904', '906', '914', '916', '925', '936', '941', '946', '960', '966', '968', '979', '984', '986', '993', '1004', '1020', '1027', '1032', '1042', '1048', '1049', '1050', '1051', '1060', '1061', '1062', '1067', '1068', '1069', '1080', '1082', '1084', '1085', '1089', '1091', '1095', '1098', '1100', '1108', '1109', '1111', '1118', '1123', '1125', '1126', '1127', '1140', '1142', '1155', '1165', '1167', '1168', '1172', '1173', '1175', '1184', '1187', '1189', '1193', '1195', '1197', '1203', '1208', '1210', '1215', '1219', '1222', '1223', '1225', '1228', '1235', '1239', '1245', '1248', '1266', '1271', '1278', '1289', '1296', '1306', '1310', '1322', '1324', '1330', '1331', '1332', '1333', '1335', '1347', '1348', '1353', '1360', '1362', '1363', '1372', '1374', '1378', '1379', '1383', '1393', '1400', '1409', '1411', '1413', '1416', '1421', '1424', '1439', '1445', '1455', '1457', '1463', '1464', '1467', '1470', '1472', '1479', '1481', '1487', '1489', '1490', '1492', '1503', '1506', '1508', '1512', '1514', '1515', '1516', '1517', '1521', '1523', '1527', '1530', '1531', '1534', '1540', '1542', '1545', '1553', '1557', '1559', '1569', '1573', '1576', '1580', '1585', '1597', '1604', '1605', '1606', '1607', '1608', '1609', '1611', '1614', '1618', '1619', '1624', '1625', '1627', '1630', '1633', '1634', '1639', '1646', '1650', '1653', '1654', '1656', '1659', '1672', '1674', '1685', '1692', '1708', '1710', '1712', '1713', '1720', '1721', '1725', '1726', '1733', '1735', '1738', '1741', '1745', '1746', '1751', '1760', '1762', '1764', '1773', '1778', '1779', '1781', '1782', '1786', '1791', '1793', '1796', '1803', '1805', '1807', '1812', '1814', '1819', '1823', '1827', '1829', '1834', '1844', '1845', '1848', '1850', '1858', '1860', '1862', '1863', '1865', '1867', '1868', '1870', '1877', '1883', '1894', '1898', '1899', '1900', '1901', '1904', '1905', '1908', '1912', '1913', '1919', '1922', '1923', '1925', '1929', '1932', '1935', '1937', '1939', '1941', '1950', '1955', '1960', '1961', '1965', '1968', '1971', '1975', '1983', '1993', '1997', '2001', '2003', '2006', '2008', '2013', '2021', '2022', '2026', '2031', '2032', '2034', '2039', '2043', '2045']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('float', []) : 387 | ['47', '61', '67', '75', '146', ...]\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 881 | ['0', '1', '2', '4', '5', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', [])     : 408 | ['1', '2', '8', '9', '11', ...]\n",
      "\t\t('int', ['bool']) : 473 | ['0', '4', '5', '7', '12', ...]\n",
      "\t2.6s = Fit runtime\n",
      "\t881 features in original data used to generate 881 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.69 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 2.66s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Large model count detected (112 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
      "\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
      "\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 108 L1 models ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 24.04s of the 36.05s of remaining time.\n",
      "\t-0.2062\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.04s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 23.8s of the 35.82s of remaining time.\n",
      "\t-0.2038\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.03s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 23.59s of the 35.61s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=24, gpus=0, memory=0.02%)\n",
      "\t-0.1838\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.04s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 21.14s of the 33.15s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=24, gpus=0, memory=0.02%)\n",
      "\t-0.1888\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.03s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L1 ... Training model for up to 18.77s of the 30.79s of remaining time.\n",
      "\t-0.1929\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.71s\t = Training   runtime\n",
      "\t0.11s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 17.83s of the 29.84s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=24, gpus=0, memory=0.03%)\n",
      "\t-0.1853\t = Validation score   (-root_mean_squared_error)\n",
      "\t4.7s\t = Training   runtime\n",
      "\t0.25s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE_BAG_L1 ... Training model for up to 11.72s of the 23.74s of remaining time.\n",
      "\t-0.1947\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.61s\t = Training   runtime\n",
      "\t0.13s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 10.84s of the 22.86s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=24, gpus=0, memory=0.00%)\n",
      "\t-0.198\t = Validation score   (-root_mean_squared_error)\n",
      "\t3.4s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L1 ... Training model for up to 6.0s of the 18.01s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=24, gpus=0, memory=0.04%)\n",
      "\t-0.1883\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.16s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 3.45s of the 15.47s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=24, gpus=0, memory=0.00%)\n",
      "\t-0.1886\t = Validation score   (-root_mean_squared_error)\n",
      "\t4.14s\t = Training   runtime\n",
      "\t0.99s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 36.06s of the 9.58s of remaining time.\n",
      "\tEnsemble Weights: {'LightGBMXT_BAG_L1': 0.4, 'NeuralNetTorch_BAG_L1': 0.32, 'CatBoost_BAG_L1': 0.2, 'XGBoost_BAG_L1': 0.08}\n",
      "\t-0.1771\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 106 L2 models ...\n",
      "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 9.52s of the 9.48s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=24, gpus=0, memory=0.02%)\n",
      "\t-0.1789\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.81s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L2 ... Training model for up to 7.31s of the 7.27s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=24, gpus=0, memory=0.02%)\n",
      "\t-0.1816\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.81s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L2 ... Training model for up to 5.13s of the 5.09s of remaining time.\n",
      "\t-0.1822\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.59s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L2 ... Training model for up to 4.28s of the 4.24s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=24, gpus=0, memory=0.03%)\n",
      "\t-0.176\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.48s\t = Training   runtime\n",
      "\t0.26s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE_BAG_L2 ... Training model for up to 1.36s of the 1.32s of remaining time.\n",
      "\t-0.1797\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.76s\t = Training   runtime\n",
      "\t0.11s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 36.06s of the -1.41s of remaining time.\n",
      "\tEnsemble Weights: {'CatBoost_BAG_L2': 0.476, 'LightGBMXT_BAG_L1': 0.19, 'ExtraTreesMSE_BAG_L2': 0.19, 'NeuralNetTorch_BAG_L1': 0.143}\n",
      "\t-0.1749\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.02s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 40.21s ... Best model: WeightedEnsemble_L3 | Estimated inference throughput: 25.6 rows/s (44 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20240625_153824\")\n"
     ]
    }
   ],
   "source": [
    "predictor = TabularPredictor(\n",
    "    label=\"value\",\n",
    "    problem_type=\"regression\",\n",
    ").fit(df_train, time_limit=60, presets=\"best_quality\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use matplotlib for plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'pred')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "metrics = predictor.evaluate(df_test, silent=True)\n",
    "\n",
    "\n",
    "y_pred = predictor.predict(df_test.drop(columns=[\"value\"]))\n",
    "y_pred\n",
    "\n",
    "ax.plot(y_pred, df_test[\"value\"], \"o\")\n",
    "ax.plot([0, 1], [0, 1], \"k--\")\n",
    "ax.text(0.1, 0.9, f\"R2 = {metrics['r2']:.3f}\", transform=ax.transAxes)\n",
    "ax.set_title(\"Testdata set\")\n",
    "ax.set_ylabel(\"truth\")\n",
    "ax.set_xlabel(\"pred\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
